## Project Title: Multi-Modalities Fusion for Hateful Meme Classification

### Brief Description:
The proliferation of social media content, including a significant amount of hateful material, presents a challenge for automated models to accurately classify hate speech, especially when it is implicit and subtle. This project focused on developing a multimodal classifier capable of identifying implicit hate speech in memes by combining textual and visual data. By leveraging advanced models like Vision Transformer (ViT) for images and HateBERT for text, the project aimed to enhance the classifier's ability to detect hate speech that traditional unimodal models might miss.

### Technologies Used:
- **Programming Languages:** Python, PyTorch
- **Models:** Vision Transformer (ViT), HateBERT
- **Techniques:** Contrastive Learning, Cross-Attention, Self-Attention
- **Datasets:** Hateful Memes Challenge, TOXIGEN, HarMeme

### My Contributions:
- **Multi-Modal Implementation:**
  - Implemented the multimodal architecture combining ViT for image processing and HateBERT for text analysis.
  - Integrated contrastive learning, cross-attention, and self-attention mechanisms to enhance the model's performance.
  
- **Literature Review:**
  - Conducted the literature review, focusing on identifying and understanding the latest approaches in multimodal hate speech classification.

### Outcome/Impact:
This project successfully demonstrated the potential of multimodal approaches in identifying implicit hate speech in memes. By combining text and image data, the developed model outperformed several existing benchmarks, particularly on less challenging datasets like HarMeme. The insights gained from this project contribute to the ongoing efforts to improve hate speech detection on social media platforms.

### Report:
Find a complete report in the file titled `Hateful_meme_classification.pdf` inside the folder `Multi-Model-Hateful-Meme-Classification-DeepLearning`.

### [Back to Main README](../README.md)